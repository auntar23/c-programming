{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOo6cN0CMxAUifZiYtMmt2S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auntar23/c-programming/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai6B7QrotWiB",
        "outputId": "aae91836-a349-473f-b5aa-a3ccc30c2bce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Activation, AveragePooling2D, Add, DepthwiseConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Softmax\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "nim9R5i9toiA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your dataset on Google Drive\n",
        "dataset_path = '/content/drive/MyDrive/Dataset cover and stego 1000'"
      ],
      "metadata": {
        "id": "jKdS8O9otqbk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUPNd93jt1bC",
        "outputId": "341c9c64-9b84-450b-942d-02430e1d9fce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, SeparableConv2D, GlobalAveragePooling2D, AveragePooling2D, Activation, BatchNormalization"
      ],
      "metadata": {
        "id": "yMPGYLeZt6Pc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def steganalysis_model(input_shape=(256, 256, 1)):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Preprocessing stage with non-trainable filters\n",
        "    x = Conv2D(40, (3, 3), padding='same', activation='elu', trainable=False)(inputs)\n",
        "\n",
        "    # Multiple convolutional layers\n",
        "    for _ in range(10):\n",
        "        x = Conv2D(64, (3, 3), padding='same', activation='elu')(x)\n",
        "\n",
        "    # 4 Average Pooling layers\n",
        "    for _ in range(4):\n",
        "        x = AveragePooling2D((2, 2), strides=2)(x)\n",
        "\n",
        "    # 4 Separable Convolutional layers\n",
        "    for _ in range(4):\n",
        "        x = SeparableConv2D(64, (3, 3), padding='same', activation='elu')(x)\n",
        "\n",
        "    # 5 Depthwise Convolutional layers\n",
        "    for _ in range(5):\n",
        "        x = SeparableConv2D(64, (3, 3), padding='same', activation='elu', depth_multiplier=1)(x)\n",
        "\n",
        "    # Global Average Pooling layer\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Softmax activation for classification\n",
        "    outputs = Activation('softmax')(x)\n",
        "\n",
        "    # Model\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = steganalysis_model()"
      ],
      "metadata": {
        "id": "HrX-WGSnt93q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yJCnqebEuGiU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import imageio\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Path to the directory containing PGM images\n",
        "pgm_dataset_path = '/content/drive/MyDrive/Dataset cover and stego 1000'\n",
        "\n",
        "# Load PGM images and labels\n",
        "def load_pgm_images_and_labels(folder_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for class_folder in os.listdir(folder_path):\n",
        "        class_path = os.path.join(folder_path, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            label = 1 if class_folder == 'stego' else 0  # Assuming 'stego' is 1 and 'cover' is 0\n",
        "            for filename in os.listdir(class_path):\n",
        "                if filename.endswith('.pgm'):\n",
        "                    img_path = os.path.join(class_path, filename)\n",
        "                    image = imageio.imread(img_path)\n",
        "                    images.append(image)\n",
        "                    labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load PGM images and labels\n",
        "pgm_images, labels = load_pgm_images_and_labels(pgm_dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0L1HIQguHVx",
        "outputId": "2fd19898-2f95-4b84-9f41-f51bd6d514cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-a5e78056867c>:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(img_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the directory containing your dataset\n",
        "dataset_path = '/content/drive/MyDrive/Dataset cover and stego 1000'\n",
        "\n",
        "# Define the classes\n",
        "classes = ['cover', 'stego']\n",
        "\n",
        "# Dictionary to store the counts for each class\n",
        "class_counts = {cls: 0 for cls in classes}\n",
        "\n",
        "# Iterate through the dataset directory\n",
        "for cls in classes:\n",
        "    class_path = os.path.join(dataset_path, cls)\n",
        "    if os.path.exists(class_path) and os.path.isdir(class_path):\n",
        "        # Count the number of images in each class\n",
        "        num_images = len([f for f in os.listdir(class_path) if f.endswith('.pgm')])\n",
        "        class_counts[cls] = num_images\n",
        "        print(f\"Number of images in {cls}: {num_images}\")\n",
        "\n",
        "# Total number of images in the dataset\n",
        "total_images = sum(class_counts.values())\n",
        "print(f\"\\nTotal number of images in the dataset: {total_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N94DvPanuToq",
        "outputId": "f5ae6bd2-661e-49ad-aced-837860e27333"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in cover: 1000\n",
            "Number of images in stego: 1000\n",
            "\n",
            "Total number of images in the dataset: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding\n",
        "num_classes = 2  # Assuming binary classification\n",
        "labels_one_hot = to_categorical(labels, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "rmoreZZMumoA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
        "    pgm_images, labels_one_hot, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Split the remaining data into validation and test sets\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "    temp_images, temp_labels, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Add channel dimension for single-channel images\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "val_images = np.expand_dims(val_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "val_images = val_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Validation images shape:\", val_images.shape)\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Validation labels shape:\", val_labels.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DScjH6RDzftP",
        "outputId": "7d5f8195-d321-482f-bcb3-5d9bc6f5b89d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images shape: (1400, 256, 256, 1)\n",
            "Validation images shape: (300, 256, 256, 1)\n",
            "Test images shape: (300, 256, 256, 1)\n",
            "Train labels shape: (1400, 2)\n",
            "Validation labels shape: (300, 2)\n",
            "Test labels shape: (300, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, SeparableConv2D, DepthwiseConv2D, GlobalAveragePooling2D, Dense, Input\n",
        "\n",
        "# Define your model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(Conv2D(30, (3, 3), padding='same', activation='elu', input_shape=(256, 256, 1), trainable=False))\n",
        "\n",
        "# Additional Convolutional layers\n",
        "for _ in range(10):\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='elu'))\n",
        "\n",
        "# Max pooling layers\n",
        "for _ in range(4):\n",
        "    model.add(MaxPooling2D((2, 2), strides=2))\n",
        "\n",
        "# Separable convolutional layers\n",
        "for _ in range(4):\n",
        "    model.add(SeparableConv2D(64, (3, 3), padding='same', activation='elu'))\n",
        "\n",
        "# Depthwise Convolutional layers\n",
        "for _ in range(5):\n",
        "    model.add(DepthwiseConv2D(3, padding='same', activation='elu'))\n",
        "\n",
        "# Global Average Pooling\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(Dense(2, activation='softmax'))  # Assuming binary classification, adjust for more classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oMuX9Tnuuul",
        "outputId": "991b68c6-65d1-43c8-9545-f9b829dc3b9f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_44 (Conv2D)          (None, 256, 256, 30)      300       \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 256, 256, 64)      17344     \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 128, 128, 64)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 64, 64, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPooli  (None, 32, 32, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPooli  (None, 16, 16, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " separable_conv2d_21 (Separ  (None, 16, 16, 64)        4736      \n",
            " ableConv2D)                                                     \n",
            "                                                                 \n",
            " separable_conv2d_22 (Separ  (None, 16, 16, 64)        4736      \n",
            " ableConv2D)                                                     \n",
            "                                                                 \n",
            " separable_conv2d_23 (Separ  (None, 16, 16, 64)        4736      \n",
            " ableConv2D)                                                     \n",
            "                                                                 \n",
            " separable_conv2d_24 (Separ  (None, 16, 16, 64)        4736      \n",
            " ableConv2D)                                                     \n",
            "                                                                 \n",
            " depthwise_conv2d_15 (Depth  (None, 16, 16, 64)        640       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " depthwise_conv2d_16 (Depth  (None, 16, 16, 64)        640       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " depthwise_conv2d_17 (Depth  (None, 16, 16, 64)        640       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " depthwise_conv2d_18 (Depth  (None, 16, 16, 64)        640       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " depthwise_conv2d_19 (Depth  (None, 16, 16, 64)        640       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " global_average_pooling2d_4  (None, 64)                0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 372270 (1.42 MB)\n",
            "Trainable params: 371970 (1.42 MB)\n",
            "Non-trainable params: 300 (1.17 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_images, train_labels,\n",
        "    validation_data=(val_images, val_labels),\n",
        "    epochs=5,  # Adjust the number of epochs based on your needs\n",
        "    batch_size=16\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpONGodeu3CR",
        "outputId": "31a99bec-7c8e-432b-ed47-9c4dd02cfad6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "88/88 [==============================] - 62s 646ms/step - loss: 0.6936 - accuracy: 0.4957 - val_loss: 0.6935 - val_accuracy: 0.4900\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 56s 635ms/step - loss: 0.6937 - accuracy: 0.4771 - val_loss: 0.6932 - val_accuracy: 0.4900\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 54s 620ms/step - loss: 0.6938 - accuracy: 0.4871 - val_loss: 0.6934 - val_accuracy: 0.4900\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 56s 636ms/step - loss: 0.6934 - accuracy: 0.4843 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 56s 635ms/step - loss: 0.6936 - accuracy: 0.4943 - val_loss: 0.6935 - val_accuracy: 0.4900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have test_images and test_labels\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test Accuracy: {test_accuracy}, Test Loss: {test_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzhgw2tuwKDA",
        "outputId": "5134245f-cde6-48ab-af84-a9054c39f008"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 4s 367ms/step - loss: 0.6931 - accuracy: 0.5033\n",
            "Test Accuracy: 0.503333330154419, Test Loss: 0.6931399703025818\n"
          ]
        }
      ]
    }
  ]
}